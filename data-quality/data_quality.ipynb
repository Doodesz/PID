{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f5c669",
   "metadata": {},
   "source": [
    "# Data Quality & Validation Workshop\n",
    "Welcome! Today we‚Äôll practice diagnosing and fixing data quality issues in a mock e-commerce dataset using both Python (Pandas) and SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e3881f",
   "metadata": {},
   "source": [
    "## How today will work\n",
    "1. Review why trustworthy data underpins analytics and decisions.\n",
    "2. Get hands-on with common validation checks:\n",
    "   - Missing values\n",
    "   - Duplicates\n",
    "   - Invalid data formats\n",
    "   - Outliers\n",
    "   - Foreign key mismatches\n",
    "3. Investigate a realistic incident: inconsistent marketing segmentation.\n",
    "4. Design both tactical fixes and long-term safeguards.\n",
    "\n",
    "üßë‚Äçüè´ **Interactive flow:** After each section, decide what you want to inspect next. Ask for hints if stuck and capture your observations in the provided scratch cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3b5d57",
   "metadata": {},
   "source": [
    "## Why data quality matters\n",
    "- **Accurate analytics:** A single bad column can throw off KPIs, forecasts, or segmentation models.\n",
    "- **Confident decisions:** Leadership won‚Äôt trust dashboards if the numbers keep shifting unexpectedly.\n",
    "- **Efficient operations:** Better data upstream means fewer downstream fire drills.\n",
    "- **Compliance & governance:** Documented, repeatable checks keep audits and risk reviews smooth.\n",
    "\n",
    "‚ö°Ô∏è *Prompt:* Before diving into code, jot down one recent situation where messy data slowed down your team."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff0ded4",
   "metadata": {},
   "source": [
    "## Mock data setup\n",
    "We‚Äôll simulate two tables:\n",
    "- `customers` (`customer_id`, `first_name`, `last_name`, `email`, `age`, `signup_date`)\n",
    "- `transactions` (`transaction_id`, `customer_id`, `order_date`, `amount`, `payment_method`)\n",
    "\n",
    "The sample data intentionally includes quality issues so you can practice finding them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f5dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "customers = pd.DataFrame([\n",
    "    {\"customer_id\": 1, \"first_name\": \"Alice\", \"last_name\": \"Nguyen\", \"email\": \"alice@example.com\", \"age\": 34, \"signup_date\": \"2023-01-05\"},\n",
    "    {\"customer_id\": 2, \"first_name\": \"Ben\", \"last_name\": \"Silva\", \"email\": None, \"age\": 28, \"signup_date\": \"2023-02-14\"},\n",
    "    {\"customer_id\": 3, \"first_name\": \"Chloe\", \"last_name\": \"Patel\", \"email\": \"not-an-email\", \"age\": -2, \"signup_date\": \"2023-03-22\"},\n",
    "    {\"customer_id\": 4, \"first_name\": \"Diego\", \"last_name\": \"O‚ÄôBrien\", \"email\": \"diego@sample.org\", \"age\": 150, \"signup_date\": \"2025-12-30\"},\n",
    "    {\"customer_id\": 5, \"first_name\": \"Alice\", \"last_name\": \"Nguyen\", \"email\": \"alice@example.com\", \"age\": 34, \"signup_date\": \"2023-01-05\"},\n",
    "    {\"customer_id\": 5, \"first_name\": \"Alice\", \"last_name\": \"Nguyen\", \"email\": \"alice@example.com\", \"age\": 34, \"signup_date\": \"2023-01-05\"}\n",
    "])\n",
    "\n",
    "transactions = pd.DataFrame([\n",
    "    {\"transaction_id\": 101, \"customer_id\": 1, \"order_date\": \"2023-03-10\", \"amount\": 120.0, \"payment_method\": \"card\"},\n",
    "    {\"transaction_id\": 102, \"customer_id\": 1, \"order_date\": \"2023-04-18\", \"amount\": 20000.0, \"payment_method\": \"card\"},\n",
    "    {\"transaction_id\": 103, \"customer_id\": 99, \"order_date\": \"2023-05-02\", \"amount\": 85.5, \"payment_method\": \"paypal\"},\n",
    "    {\"transaction_id\": 104, \"customer_id\": 2, \"order_date\": \"2023-05-20\", \"amount\": np.nan, \"payment_method\": \"card\"},\n",
    "    {\"transaction_id\": 105, \"customer_id\": 3, \"order_date\": \"2023-06-15\", \"amount\": 45.0, \"payment_method\": \"gift_card\"}\n",
    "])\n",
    "\n",
    "customers, transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e4c46a",
   "metadata": {},
   "source": [
    "### Choose your first validation\n",
    "Call `show_menu()` below to display the available checks. Then run the specific section you want to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f67817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_menu():\n",
    "    menu = [\n",
    "        \"missing_values\",\n",
    "        \"duplicates\",\n",
    "        \"invalid_formats\",\n",
    "        \"outliers\",\n",
    "        \"foreign_keys\"\n",
    "    ]\n",
    "    print(\"Pick the next check to run by jumping to that section. Options:\")\n",
    "    for item in menu:\n",
    "        print(f\" - {item}\")\n",
    "\n",
    "show_menu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e644a",
   "metadata": {},
   "source": [
    "## 1. Missing values\n",
    "üîç **Prompt:** What columns worry you most if they contain nulls? Add them to the list below and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ae4485",
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_columns = ['customer_id', 'email']  # ‚Üê customize if you like\n",
    "missing_summary = customers.isna().sum().sort_values(ascending=False)\n",
    "print(\"Missing values per column:\")\n",
    "display(missing_summary)\n",
    "\n",
    "critical_nulls = customers[customers[critical_columns].isna().any(axis=1)]\n",
    "print(\"Rows with critical nulls:\")\n",
    "display(critical_nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fca2cc",
   "metadata": {},
   "source": [
    "üí° **Hint:** `DataFrame.isna().sum()` gets counts per column; use `.any(axis=1)` to filter rows where any critical column is null.\n",
    "‚úçÔ∏è **Reflection:** Are null emails acceptable here? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d756ab7",
   "metadata": {},
   "source": [
    "**SQL equivalent**\n",
    "```sql\n",
    "SELECT\n",
    "  SUM(CASE WHEN email IS NULL THEN 1 ELSE 0 END) AS email_nulls,\n",
    "  SUM(CASE WHEN customer_id IS NULL THEN 1 ELSE 0 END) AS customer_id_nulls\n",
    "FROM customers;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bef2a8",
   "metadata": {},
   "source": [
    "## 2. Duplicates\n",
    "üîç **Prompt:** Decide whether to look for row-level duplicates, business key duplicates, or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80541ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_duplicates = customers[customers.duplicated()]\n",
    "print(\"Row-level duplicates:\")\n",
    "display(row_duplicates)\n",
    "\n",
    "email_duplicates = customers[customers.duplicated(subset=['email'], keep=False)]\n",
    "print(\"Email duplicates:\")\n",
    "display(email_duplicates.sort_values('email'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de454542",
   "metadata": {},
   "source": [
    "üí° **Hint:** Use `keep=False` to see every instance of a duplicated key, not just later occurrences.\n",
    "‚úçÔ∏è **Reflection:** Are these duplicates legitimate (e.g., joint accounts) or errors to resolve?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20287a7",
   "metadata": {},
   "source": [
    "**SQL equivalent**\n",
    "```sql\n",
    "SELECT email, COUNT(*) AS occurrences\n",
    "FROM customers\n",
    "GROUP BY email\n",
    "HAVING COUNT(*) > 1;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1609fb",
   "metadata": {},
   "source": [
    "## 3. Invalid data formats\n",
    "üîç **Prompt:** Pick one: emails, ages, or signup dates. What rule does the data need to meet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bfd7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_email = customers[~customers['email'].fillna('').str.match(r'^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$')]\n",
    "print(\"Emails failing regex validation:\")\n",
    "display(invalid_email)\n",
    "\n",
    "invalid_age = customers[(customers['age'] <= 0) | (customers['age'] > 110) | (customers['age'].isna())]\n",
    "print(\"Ages outside acceptable range:\")\n",
    "display(invalid_age)\n",
    "\n",
    "signup = pd.to_datetime(customers['signup_date'], errors='coerce')\n",
    "future_signup = customers[signup > pd.Timestamp.now()]\n",
    "print(\"Future signup dates:\")\n",
    "display(future_signup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f412990f",
   "metadata": {},
   "source": [
    "üí° **Hint:** Use `errors='coerce'` with `to_datetime` to convert broken dates into `NaT` for easy filtering.\n",
    "‚úçÔ∏è **Reflection:** Which rule should be enforced at data entry vs. cleaned downstream?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce70a81",
   "metadata": {},
   "source": [
    "**SQL equivalent**\n",
    "```sql\n",
    "SELECT customer_id, email\n",
    "FROM customers\n",
    "WHERE email NOT LIKE '%_@__%.__%';\n",
    "\n",
    "SELECT customer_id, age\n",
    "FROM customers\n",
    "WHERE age <= 0 OR age > 110 OR age IS NULL;\n",
    "\n",
    "SELECT customer_id, signup_date\n",
    "FROM customers\n",
    "WHERE signup_date::date > CURRENT_DATE;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52184dd3",
   "metadata": {},
   "source": [
    "## 4. Outliers in transaction values\n",
    "üîç **Prompt:** Define what counts as an outlier for this business. Are we using Tukey‚Äôs IQR rule or z-scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9887bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = transactions['amount'].quantile(0.25)\n",
    "q3 = transactions['amount'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "print(f\"IQR bounds: {lower_bound:.2f} to {upper_bound:.2f}\")\n",
    "outliers = transactions[(transactions['amount'] < lower_bound) | (transactions['amount'] > upper_bound)]\n",
    "print(\"Potential outlier transactions:\")\n",
    "display(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527282b8",
   "metadata": {},
   "source": [
    "üí° **Hint:** Pair the numeric check with business knowledge. A $20,000 order might be legit for a B2B customer but not for a retail shopper.\n",
    "‚úçÔ∏è **Reflection:** What follow-up analysis would you do before flagging this to finance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505ef914",
   "metadata": {},
   "source": [
    "**SQL equivalent**\n",
    "```sql\n",
    "WITH stats AS (\n",
    "  SELECT\n",
    "    percentile_cont(0.25) WITHIN GROUP (ORDER BY amount) AS q1,\n",
    "    percentile_cont(0.75) WITHIN GROUP (ORDER BY amount) AS q3\n",
    "  FROM transactions\n",
    ")\n",
    "SELECT t.*\n",
    "FROM transactions t\n",
    "CROSS JOIN stats s\n",
    "WHERE t.amount < s.q1 - 1.5 * (s.q3 - s.q1)\n",
    "   OR t.amount > s.q1 + 1.5 * (s.q3 - s.q1);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d613690",
   "metadata": {},
   "source": [
    "## 5. Foreign key mismatches\n",
    "üîç **Prompt:** What downstream processes rely on `customer_id` being valid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24ceab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_missing_customers = transactions[~transactions['customer_id'].isin(customers['customer_id'])]\n",
    "print(\"Transactions referencing unknown customers:\")\n",
    "display(transactions_missing_customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b6de5",
   "metadata": {},
   "source": [
    "üí° **Hint:** After spotting mismatches, trace them back to ingestion logs or source system exports to understand how they slipped in.\n",
    "‚úçÔ∏è **Reflection:** Would you drop, correct, or quarantine these rows? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bad4ed",
   "metadata": {},
   "source": [
    "**SQL equivalent**\n",
    "```sql\n",
    "SELECT t.*\n",
    "FROM transactions t\n",
    "LEFT JOIN customers c ON t.customer_id = c.customer_id\n",
    "WHERE c.customer_id IS NULL;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e2fe7",
   "metadata": {},
   "source": [
    "## Incident drill: inconsistent marketing segmentation\n",
    "**Scenario:** Marketing reports that the \"High Value\" segment in their campaign tool shows 42 customers, but the analytics dashboard shows only 31.\n",
    "\n",
    "### Your tasks\n",
    "1. Use the validation checks above to find at least two issues that could cause divergent segment counts.\n",
    "2. Document the suspected root cause(s) in the scratch cell below.\n",
    "3. Recommend an immediate fix (e.g., data backfill, re-run segmentation, manual remediation).\n",
    "4. Propose long-term preventive measures (automated tests, data contracts, ETL guardrails).\n",
    "\n",
    "> **Need a hint?** Look closely at duplicate customers and outlier transactions inflating spend-driven segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6dd82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch pad: capture your findings and action plan here.\n",
    "incident_notes = {\n",
    "    'root_causes': [],  # e.g., duplicate customers, invalid spend\n",
    "    'immediate_fix': '',\n",
    "    'long_term_prevention': []\n",
    "}\n",
    "incident_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305707fb",
   "metadata": {},
   "source": [
    "## Wrap-up checklist\n",
    "- [ ] Reviewed missing values and their impact\n",
    "- [ ] Assessed duplicates and business key quality\n",
    "- [ ] Validated formats and ranges\n",
    "- [ ] Evaluated outlier handling strategy\n",
    "- [ ] Confirmed referential integrity\n",
    "\n",
    "üéØ **Next steps:** Decide which checks to automate in your production pipeline and how frequently to monitor them."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
